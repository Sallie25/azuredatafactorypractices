{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "deeptechdatafactory"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/fitnessgympipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "This pipeline shows the ETL process carried out on  fitness_gym dataset in completion of the task assigned by the deeptech data engineering programme. Here we configure a copy activity in ADF to transfer data from a source to sink container in azure blob storage",
				"activities": [
					{
						"name": "Activity 1",
						"description": "Move data from input to output container",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "ExcelSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "fitness_gym_input_dataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "fitnessgym_sink_dataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/food_delivery_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "This pipeline configures a copy activity in ADF to ingest data from Azure Blob Storage and automatically create and load it into a new table in Azure SQL Database.",
				"activities": [
					{
						"name": "Activity1",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "AzureSqlSink",
								"writeBehavior": "insert",
								"sqlWriterUseTableLock": false,
								"tableOption": "autoCreate",
								"disableMetricsCollection": false
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "food_delivery_input_dataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "food_delivery_sql_sink_dataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/typicode_api_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Building a pipeline by ingesting data in json format through n API",
				"activities": [
					{
						"name": "API to Blob copy activity",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET",
								"paginationRules": {
									"supportRFC5988": "true"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "typicode_source_api_data",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "API_csv_sink_data",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Blob to DB copy activity",
						"description": "This creates a copy of the data that was ingested to be stored in the SQL database for the software team.",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "API to Blob copy activity",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "AzureSqlSink",
								"writeBehavior": "insert",
								"sqlWriterUseTableLock": false,
								"tableOption": "autoCreate",
								"disableMetricsCollection": false
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "API_csv_sink_data",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "API_sql_test_data",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/PenSales_dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "PenSaless_data",
								"type": "DatasetReference"
							},
							"name": "penSalesdataflow"
						},
						{
							"dataset": {
								"referenceName": "penCostdata",
								"type": "DatasetReference"
							},
							"name": "penCostdataflow"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "PenSalesdata",
								"type": "DatasetReference"
							},
							"name": "PenSalesdata"
						}
					],
					"transformations": [
						{
							"name": "joinedpenSalesCostdata"
						},
						{
							"name": "selectRequiredcolumns"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Customer as string,",
						"          Item as string,",
						"          {Pen Cost} as string,",
						"          {Shipping Cost} as string,",
						"          {Purchase Date} as string,",
						"          {Delivery Date} as string,",
						"          Review as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> penSalesdataflow",
						"source(output(",
						"          Pen as string,",
						"          Cost as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> penCostdataflow",
						"penSalesdataflow, penCostdataflow join(Item == Pen,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinedpenSalesCostdata",
						"joinedpenSalesCostdata select(mapColumn(",
						"          Customer,",
						"          Item,",
						"          {Pen Cost},",
						"          {Shipping Cost},",
						"          {Purchase Date},",
						"          {Delivery Date},",
						"          Review",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectRequiredcolumns",
						"selectRequiredcolumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> PenSalesdata"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/bookSalesdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "BookSales_April_data",
								"type": "DatasetReference"
							},
							"name": "bookSalesApr",
							"description": "Added a booksales dataset for the month of April"
						},
						{
							"dataset": {
								"referenceName": "bookSalesMay",
								"type": "DatasetReference"
							},
							"name": "bookSalesMay",
							"description": "Added a booksales dataset for the month of May source dataset"
						},
						{
							"dataset": {
								"referenceName": "bookSalesJune_data",
								"type": "DatasetReference"
							},
							"name": "bookSalesJune",
							"description": "Added a booksales dataset for the month of June source dataset"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Booksalesdata",
								"type": "DatasetReference"
							},
							"name": "BooksSalesDataforallMonths"
						}
					],
					"transformations": [
						{
							"name": "ConcatenationofAprtoJune"
						}
					],
					"scriptLines": [
						"source(output(",
						"          {Purchase ID} as string,",
						"          {Customer ID} as string,",
						"          Book as string,",
						"          Audience as string,",
						"          Genre as string,",
						"          Price as string,",
						"          {Book Rating} as string,",
						"          {Purchase Location} as string,",
						"          {Purchase Date} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false) ~> bookSalesApr",
						"source(output(",
						"          {Purchase ID} as string,",
						"          {Customer ID} as string,",
						"          Book as string,",
						"          Audience as string,",
						"          Genre as string,",
						"          Price as string,",
						"          {Book Rating} as string,",
						"          {Purchase Location} as string,",
						"          {Purchase Date} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> bookSalesMay",
						"source(output(",
						"          {Purchase ID} as string,",
						"          {Customer ID} as string,",
						"          Book as string,",
						"          Audience as string,",
						"          Genre as string,",
						"          Price as string,",
						"          {Book Rating} as string,",
						"          {Purchase Location} as string,",
						"          {Purchase Date} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> bookSalesJune",
						"bookSalesApr, bookSalesMay, bookSalesJune union(byName: true)~> ConcatenationofAprtoJune",
						"ConcatenationofAprtoJune sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> BooksSalesDataforallMonths"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Schedule_trigger_fitnessgym')]",
			"type": "Microsoft.DataFactory/factories/triggers",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "fitnessgympipeline",
							"type": "PipelineReference"
						},
						"parameters": {}
					}
				],
				"type": "ScheduleTrigger",
				"typeProperties": {
					"recurrence": {
						"frequency": "Day",
						"interval": 29,
						"startTime": "2025-11-27T00:00:00",
						"timeZone": "W. Central Africa Standard Time",
						"schedule": {}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/pipelines/fitnessgympipeline')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Pen_Sales_dataflow_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Pen_Sales_dataflow",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "PenSales_dataflow",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"penSalesdataflow": {},
									"penCostdataflow": {},
									"PenSalesdata": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/PenSales_dataflow')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/BookSales_dataflow_pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "BookSales_dataflow",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "bookSalesdataflow",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"bookSalesApr": {},
									"bookSalesMay": {},
									"bookSalesJune": {},
									"BooksSalesDataforallMonths": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/bookSalesdataflow')]"
			]
		}
	]
}